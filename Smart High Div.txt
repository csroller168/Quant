"""
Copyright Chris Short 2017
Use is unauthorized without written permission

TODO
- Try to replace existing unemployment logic with calls like result = run_pipeline(make_pipeline(), '2015-05-05', '2015-05-05')
- test for momentum/unempl favorability and short market if unfavorable
- set base leverage for long/short based on favorability indicators
- refine screens

Ranking algorithm notes:
    - screen for low P/E, high book val/share
    - consider brand favorability factor
    - use smart screen point-based ranks
    - rank longs and shorts separately

Calculate long and short buckets:
    - use top X% of long/short ranks
    - optimize weights to minimize covariance
        - https://www.quantopian.com/posts/quantopian-lecture-series-the-good-the-bad-and-the-correlated

- rebalance monthly
- Use same in/out indicators - unempl + SPY momentum
- when in the market, buy n% long, m% short
- when out of market, short 50% short bucket, 50% SPY
- Experiment:  Short only stocks in one sector e.g. retail

"""
from quantopian.algorithm import attach_pipeline, pipeline_output
from quantopian.pipeline import Pipeline, CustomFactor
from quantopian.pipeline.data import morningstar
from quantopian.pipeline.data.quandl import fred_unrate
from quantopian.pipeline.filters.morningstar import Q500US
from quantopian.pipeline.data.builtin import USEquityPricing
import numpy as np
import scipy

# Constants
LoggingEnabled = False
UTILITIES_SECTOR = 207
NUM_LONG = 15
NUM_SHORT = 7

class UnemplData(object):
    def __init__(self, pastData):
        self.pastData = pastData
    
    def cache_latest(self, currUnempl):
        self.pastData.append(currUnempl)
    
    def is_favorable(self):
        current = self.pastData[-1]
        pastAvg = (self.pastData[-4] + self.pastData[-3] + self.pastData[-2]) / 3
        return current > pastAvg

class LongRank(CustomFactor):
    window_length = 1
    inputs = [morningstar.valuation_ratios.dividend_yield,
             morningstar.operation_ratios.ebitda_margin,
             morningstar.valuation.market_cap,
             morningstar.operation_ratios.long_term_debt_equity_ratio]
    
    def compute(self, today, assets, out, divYld, ebitdaMgn, mktCap, ltde):
        out[:] = topScore(divYld, 60, 20) + \
            topScore(divYld, 85, 30) + \
            topScore(ebitdaMgn, 60, 8) + \
            topScore(ebitdaMgn, 85, 16) + \
            topScore(mktCap, 60, 20) + \
            topScore(mktCap, 85, 30) + \
            bottomScore(ltde, 40, 14) + \
            bottomScore(ltde, 15, 24)

class ShortRank(CustomFactor):
    window_length = 1
    inputs = [morningstar.valuation_ratios.dividend_yield,
             morningstar.valuation.market_cap,
             USEquityPricing.close,
             morningstar.operation_ratios.long_term_debt_equity_ratio,
             morningstar.operation_ratios.roe,
             morningstar.valuation_ratios.pe_ratio]
    
    def compute(self, today, assets, out, divYld, mktCap, close, ltde, roe, pe):
        out[:] = bottomScore(divYld, 10, 20) + \
            bottomScore(mktCap, 50, 50) + \
            bottomScore(mktCap, 20, -50) + \
            bottomScore(close, 50, 20) + \
            bottomScore(close, 20, -20) + \
            topScore(ltde, 60, 20) + \
            topScore(ltde, 20, 20) + \
            bottomScore(roe, 40, 20) + \
            topScore(pe, 60, 20) + \
            topScore(pe, 20, 20)
            

class CurrUnemplFactor(CustomFactor):
    window_length = 1
    inputs = [fred_unrate.value]
    
    def compute(self, today, assets, out, unempl):
        out[:] = unempl

def topScore(metric, percentile, multiple):
    return multiple * (metric > np.nanpercentile(metric, percentile)).astype(int)

def bottomScore(metric, percentile, multiple):
    return multiple * (metric < np.nanpercentile(metric, percentile)).astype(int)
        
def initialize(context):
    # Initialize context variables
    context.long_bucket = []
    context.short_bucket = []
    context.rebalanceDue = True
    context.unemplData = UnemplData(build_past_data())
    
    # Rebalance once per month
    schedule_function(set_rebalance_due,
                      date_rules.month_start(days_offset=3),
                      time_rules.market_close())
    
    # Record tracking variables at the end of each day.
    schedule_function(record_vars, date_rules.every_day(), time_rules.market_close())
    
    # Try to execute orders every day to cover unexecuted orders
    schedule_function(execute_orders,
                      date_rules.every_day(),
                      time_rules.market_open(minutes=5))
    
    # Set up pipeline
    pipe = Pipeline()  
    attach_pipeline(pipe, name='pipe')
    build_pipeline(pipe)
    
def build_pipeline(pipe):
    universe_filter = Q500US()
    
    # Screen for no utilities and minimum volume
    sector_code = morningstar.asset_classification.morningstar_sector_code.latest
    sector_filter = (sector_code != UTILITIES_SECTOR)
    
    # Screens
    pipe.add(CurrUnemplFactor(), 'unempl')
    pipe.add(LongRank(), 'longRank')
    pipe.add(ShortRank(), 'shortRank')
    
    pipe.set_screen(universe_filter &
                    sector_filter)
    return pipe

def set_rebalance_due(context, data):
    context.rebalanceDue = True

def before_trading_start(context, data):
    if not context.rebalanceDue:
        return
    context.rebalanceDue = False
    
    pipe = pipeline_output('pipe')
    
    # Recalculate favorability
    context.unemplData.cache_latest(pipe['unempl'][0])
    
    # Rebalance
    context.long_bucket = get_bucket(pipe.sort_values(by='longRank', ascending=False).index[:NUM_LONG], data)
    context.short_bucket = get_bucket(pipe.sort_values(by='shortRank', ascending=False).index[:NUM_SHORT], data)

def get_bucket(symbols, data):
    prices = data.history(symbols, 'price', 300, '1d')
    daily_R = prices.pct_change().dropna()
    weights = get_reduced_correlation_weights(daily_R[symbols])
    return weights

def execute_orders(context,data):
    # Cover stocks no longer in lists
    for stock in context.portfolio.positions.iterkeys():  
        if stock not in context.long_bucket and \
            stock not in context.short_bucket and \
            data.can_trade(stock):
                order_target(stock, 0)
    
    # Buy longs
    for stock, weight in context.long_bucket.iteritems():
        if data.can_trade(stock):
            order_target_percent(stock, weight)
    
    # Sell shorts
    for stock, weight in context.short_bucket.iteritems():
        if data.can_trade(stock):
            order_target_percent(stock, -1 * weight)

def momentumFavorable(data):
    spy = symbol('SPY')
    mavgShort = data.history(spy, 'price', 50, '1d').mean()
    mavgLong = data.history(spy, 'price', 200, '1d').mean()
    return mavgShort > mavgLong
            
def record_vars(context, data):
    if not LoggingEnabled:
        return
    
    # Plot variables at the end of each day.
    long_count = 0
    short_count = 0
    leverage = context.account.leverage
    
    log_str = "holding: "
    for position in context.portfolio.positions.itervalues():
        if position.amount > 0:
            long_count += 1
            log_str += position.sid.symbol + ", "
        if position.amount < 0:
            short_count += 1
            log_str += position.sid.symbol + "(short), "
    
    # Raise an alert if short_count or leverage out of contest range
    if short_count == 0:
        short_count = 99
    if leverage > 3:
        leverage = 99
    
    # Plot the counts
    #record(num_long=long_count, num_short=short_count, currUnempl=currUnempl, pastUnempl=pastUnempl, leverage=leverage)
    record(num_long=long_count, short_count=short_count, leverage=leverage)
    log.info(log_str)

def get_reduced_correlation_weights(returns, risk_adjusted=True):
    """
    Implementation of minimum correlation algorithm.
    ref: http://cssanalytics.com/doc/MCA%20Paper.pdf
    
    :Params:
        :returns <Pandas DataFrame>:Timeseries of asset returns
        :risk_adjusted <boolean>: If True, asset weights are scaled
                                  by their standard deviations
    """
    correlations = returns.corr()
    adj_correlations = get_adjusted_cor_matrix(correlations)
    initial_weights = adj_correlations.T.mean()

    ranks = initial_weights.rank()
    ranks /= ranks.sum()

    weights = adj_correlations.dot(ranks)
    weights /= weights.sum()

    if risk_adjusted:
        weights = weights / returns.std()
        weights /= weights.sum()
    return weights

def get_adjusted_cor_matrix(cor):
    values = cor.values.flatten()
    mu = np.mean(values)
    sigma = np.std(values)
    distribution = scipy.stats.norm(mu, sigma)
    return 1 - cor.apply(lambda x: distribution.cdf(x))
    
def build_past_data():
    unempl_list = [
        5.3, 5.2, 5.2, 5.1, 4.9, 5, 4.9, 4.8, 4.9, 4.7, 4.6, 4.7,
        4.6, 4.6, 4.7, 4.3, 4.4, 4.5, 4.5, 4.5, 4.6, 4.5, 4.4, 4.4,
        4.3, 4.4, 4.2, 4.3, 4.2, 4.3, 4.3, 4.2, 4.2, 4.1, 4.1, 4,
        4, 4.1, 4, 3.8, 4, 4, 4, 4.1, 3.9, 3.9, 3.9, 3.9, 4.2, 4.2,
        4.3, 4.4, 4.3, 4.5, 4.6, 4.9, 5, 5.3, 5.5, 5.7, 5.7, 5.7,
        5.7, 5.9, 5.8, 5.8, 5.8, 5.7, 5.7, 5.7, 5.9, 6, 5.8, 5.9,
        5.9, 6, 6.1, 6.3, 6.2, 6.1, 6.1, 6, 5.8, 5.7, 5.7, 5.6, 5.8,
        5.6, 5.6, 5.6, 5.5, 5.4, 5.4, 5.5, 5.4, 5.4, 5.3, 5.4, 5.2,
        5.2, 5.1, 5, 5, 4.9, 5, 5, 5, 4.9, 4.7, 4.8, 4.7, 4.7, 4.6,
        4.6, 4.7, 4.7, 4.5, 4.4, 4.5, 4.4, 4.6, 4.5, 4.4, 4.5, 4.4,
        4.6, 4.7, 4.6, 4.7, 4.7, 4.7, 5, 5, 4.9, 5.1, 5, 5.4, 5.6,
        5.8, 6.1, 6.1, 6.5, 6.8, 7.3, 7.8, 8.3, 8.7, 9, 9.4, 9.5,
        9.5, 9.6, 9.8, 10, 9.9, 9.9, 9.8, 9.8, 9.9, 9.9, 9.6, 9.4,
        9.4, 9.5, 9.5, 9.4, 9.8, 9.3, 9.1, 9, 9, 9.1, 9, 9.1, 9, 9,
        9, 8.8, 8.6, 8.5, 8.3, 8.3, 8.2, 8.2, 8.2, 8.2, 8.2, 8.1,
        7.8, 7.8, 7.7, 7.9, 8, 7.7, 7.5, 7.6, 7.5, 7.5, 7.3, 7.3,
        7.2, 7.2, 6.9, 6.7, 6.6, 6.7, 6.7, 6.2, 6.3, 6.1, 6.2, 6.2,
        5.9, 5.7, 5.8, 5.6, 5.7, 5.5, 5.4, 5.4, 5.5, 5.3, 5.2, 5.1,
        5, 5, 5, 5, 4.9, 4.9, 5.0, 5.0, 4.7, 4.9, 4.9, 4.9, 4.9, 
        4.8, 4.6, 4.7, 4.8]
    
    # Strip future values
    now = get_datetime()
    monthOffset = ((now.year - 1997) * 12) + now.month
    unempl_list = unempl_list[:monthOffset]
    
    return unempl_list